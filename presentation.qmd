---
title: "Linear Models"
author: "George Savva (Quadram Institute Bioscience)"
echo: true
format:
  revealjs:
    theme: [dark, custom.scss]
    slide-number: true
    scrollable: true
    transition: slide
    incremental: true
  html:
    toc: true
---

# Introduction

## Session outline

-   Doing statistics the new way
-   Understanding linear models
-   Rethinking statistics in terms of LMs
-   Examples, discussion and practical work with R


## What is a linear model?

```{r echo=FALSE}
library(ggplot2)
dat <- data.frame(x=1:10, y=rnorm(10,1:10,1))
ggplot(dat , aes(x,y))  + geom_point() + stat_smooth(method="lm") + theme_bw(base_size = 18)
```

$$y=a+bx$$


## Learning objectives

-   Goals of statistics
-   Distributions and Modelling
    -   Estimating parameters
    -   Re-framing hypothesis tests as linear models
    -   Regression models for continuous and discrete predictors
    -   Interpreting and diagnosing models
-   Extensions and generalisations:
    -   Interactions (More complex hypotheses)
    -   Log-transformations
    -   Logistic regression for binary data
    -   Negative binomial regression for count data

## Aim

-   Start to understand the 'modelling' approach to statistics

-   Enable you to explore this extensive framework to do almost any kind of statistical / ML analysis

-   Become a statistician?

## About me

-   UEA lecturer in applied statistics (2013-2017)

-   Statistician at Quadram Institute Bioscience (2017-present)

-   Support for epidemiology / genomics / ecology / clinical trials / pre-clinical research

## About you!

# Models and distributions

## Motivating problem

-   Suppose we are interested in understanding the typical heights of UEA students?

-   How should we go about this?

-   Can you frame a question in mathematical / statistical terms.

    -   What should the answer look like?
    -   How will we know we are done?

. . .


:::{.callout-tip}
## Setting the question
How should you set about the scope of a statistical problem?
:::

## A distribution and a model

-   Students heights are not all the same, they have a 'distribution'.

-   What kind of data is a 'height?'

-   There is an average (central tendency) and a variance (spread).

-   We also have to assume or determine the shape of the distribution.

-   Often assume continuous variables are **independently normally distributed**



## Model

::: columns
::: {.column width="50%"}
- So, for example:

    "Heights are normally distributed with mean 180cm and standard deviation 10cm"

- We can represent this visually

- Is it likely to be good enough to describe the distribution of student heights?



:::

::: {.column width="10%"}


:::

::: {.column width="40%"}
::: {.fragment .fade-in}
```{r echo=FALSE}
#| fig-height: 10
plot.function(\(x) dnorm(x,180,10), xlim = c(120,240), xlab="Height", ylab="Density")
```
:::
:::
:::

. . .

:::{.callout-tip}
## Models
What is a model?
:::


## Writing this model mathematically

$$\text{Height} \sim N(\text{mean} , \text{variance})$$

. . .

$$H \sim N(\mu , \sigma^2)$$

. . .

We describe how individual heights arise like this:

$$h_i = \mu + \epsilon_i\quad\text{where}\quad\epsilon_i \sim N(0,\sigma^2)$$

. . .

The model has a <span style="color: green;">structural</span> part and an <span style="color: red;">error</span> part

This is the simplest linear model.



## So what is a model?

Here's our model for heights:

$$
\boxed{h_i = \mu + \epsilon_i\quad\text{where}\quad\epsilon_i \sim N(0,\sigma^2)}
$$

-   A model is a mathematical or statistical way of writing down how we think our outcome is distributed

-   The model needs to be good enough for the purpose!

    -   <span style="color: yellow;>***"All models are wrong, but some are useful"***</span>

-   It needs to link the aspects of the process we are interested in (mean $\mu$ and variance $\sigma^2$) to the data that we can observe ($h_i$).

    -   Here it's just a mean and variance but we can add things to this equation if we think they affect height.

## Do I *need* a model to do analysis?

* Yes!  Whenever you're doing any kind of statistics there is an underlying model.

* An implicit understanding of how your data came to be
    * **how the data is generated** and 
    * **how it was collected.**

* *Ad hoc* statistical procedures sometimes obscure hide these assumptions

* But with linear modelling they are more explicit.

# 'Doing' statistics

## Doing statistics with the model


* Our model: 

. . .

$$h_i = \mu + \epsilon_i\quad\text{where}\quad\epsilon_i \sim N(0,\sigma^2)$$

* If we estimate $\mu$ and $\epsilon$, we have describes the height distribution and we are done!

. . .

:::{.callout-note}
##  Key insight!

Once we have a model, *all* of statistical analysis is just estimating model parameters!
:::

## Estimating the model

* We can use data to estimate the parameters

* If we get enough $h_i$'s (at least 2!) we can estimate the values of $\mu$ and $\sigma$.

* Several ways these models are estimated:

    -   Numerical optimisation
    -   Solving with algebra
    -   Maximum likelihood
    -   Bayesian resampling

* (Not getting into this..the computer will do it)

:::{.callout-note}
We can use this logic to show that the sample mean is the best estimate for the $\mu$
:::

## Estimating the model using R

Enter some data and check it's OK:

```{r echo=TRUE}
height = c(173,177,160,165,172,182,157,175,167)
dat <- data.frame(height)
head(dat)
```

Estimate the model:

```{r echo=TRUE}
model1 <- lm( height ~ 1 , data=dat)

print(model1)

```

Display the model summary:

```{r echo=TRUE, eval=TRUE}
summary(model1)


```

## Uncertainty

Is our parameter estimate perfect? Have we completely discovered the average height of UEA students?

The confidence interval and standard error reflect the uncertainty in the estimate.

There is also uncertainty in the standard deviation estimate, but this is harder to calculate using R and we don't often use it.

## Thinking about uncertainty

What can we really say about the mean and spread of student heights?

```{r }
library(car)
linearHypothesis(model1, "(Intercept)=170")
linearHypothesis(model1, "(Intercept)=160")
linearHypothesis(model1, "(Intercept)=163.5")

confint(model1)

broom::tidy(model1 , conf.int=TRUE)
```

## Diagnostics

How good is our model? What were the model assumptions?

-   Heights are normally distributed
-   Individuals heights are independent of each other
-   (You are a representative sample of students)

Can we check these?

## Process

So we have a process for any statistical analysis!

```{mermaid}
flowchart LR
  A[Write down a model how data are linked to parameters] --> B[Estimate the parameters]
  B --> C[Does model fit data?]
  C --> D[Interpret]
  C --> A
```

## Exercise

A student questionnaire was conducted at Adelaide University.  We'll use this dataset to answer some interesting questions.

2. Consider a linear model for student height

3. Load data into R. 
    + Calculate some descriptive statistics
    + Make some plots

4. Estimate a model in R to find the distribution of student heights.

5. Diagnose the model

6. Check whether just using R to calculate the mean and standard deviation of student heights gives you the same answer.

# Extending our linear model

## Adding a predictor (finally!)

* Let's improve our model.

* Why might we want a model?

    * We might have a specific hypothesis to test

    * Or we might want to predict an outcome for a new individual

    * Or just understand the factors that contribute to our outcome in a population

* Can we improve our height prediction?  

* Can we add a factor to our model that helps to explain height?


##
Height varies with a normal distribution, but with a different average for men and women.

. . . 

We might write this as:

$$
h_i=\left\{\begin{array}{ll}
\mu_\text{male} + \epsilon_i & \text{(if male)}\\
\mu_\text{female} + \epsilon_i & \text{(if female)}
\end{array}\right.\quad\text{where}\quad\epsilon_i \sim N(0,\sigma^2)
$$

. . . 

But we would usually write this as:

$$
\boxed{h_i = \mu + \beta x_i+\epsilon_i \quad\text{where}\quad \left\{\begin{array}{ll}
x_i=1 &\text{if male;}\\
x_i=0 & \text{if female}
\end{array}\right.}
$$

. . .

Can you interpret this model?  What are the mean heights for men and women under this model? What does $\beta$ represent?

## Estimating our new model using R

Using the Adelaide survey data:

```{r }
library(readxl)
dat <- read_excel("survey.xlsx", na="NA")
dat <- dat[!is.na(dat$Sex), ]
table(dat$Sex)
dat
```

Make some plots:
```{r }
library(ggplot2)
ggplot(dat , aes(x=Sex, y=Height)) + geom_boxplot() + geom_point() + theme_bw()
```

--- 

```{r }
model2 <- lm( Height ~ Sex , data=dat)
summary(model2)
```
```
plot(model2)
```

## Diagnostic plots

```{r }
par(mfrow=c(2,2))
plot(model2)
```

## Interpretation

Look at:

* Interpreting coefficients and confidence intervals

```{r }
library(equatiomatic)
library(broom)

tidy(model2, conf.int=TRUE)
```

```{r }
extract_eq(model2, use_coefs = TRUE)
```

* Statistical significance

```{r }
coef(summary(model2))
```

* Marginal means

```{r }
emmeans::emmeans(model2 , ~Sex)
```

* Variance explained compared to a null model /  ANOVA

```{r }

```


## A continuous predictor

Let's repeat this process to understand how hand span depends on height.

```{r }
ggplot(data=dat, aes(Height, Wr.Hnd, shape=Sex)) + geom_point() 
```

Can you write down a model for how hand span depends on height?

```{r }
model3 <- lm(data=dat, Wr.Hnd ~ Height)
summary(model3)
```

## Multiple predictors

Can we better explain the hand width model?

```{r }
model4 <- lm(data=dat, Wr.Hnd ~ Height + Sex)
summary(model4)

extract_eq(model4)

```

--- 

Compare the two models.  What do they tell you?  Which is better?

```{r }
library(modelsummary)
modelsummary(list(model3, model4))
```

## Predictions

```{r }
library(patchwork)
dat$predict3 <- predict(model3, newdata = dat)
dat$predict4 <- predict(model4, newdata = dat)

(ggplot(data=dat, aes(Height, Wr.Hnd)) + geom_point() + geom_line(aes(y=predict3), lwd=1))+
(ggplot(data=dat, aes(Height, Wr.Hnd, color=Sex)) + geom_point() + geom_line(aes(y=predict4), lwd=1) +scale_color_manual(values=c("black", "red")))

```


## Interactions

Finally, we might ask if there's any evidence that the slope is different between men and women.

How could we make a model to test this hypothesis?

```{r }
model5 <- lm(data=dat, Wr.Hnd ~ Height * Sex)
summary(model5)
```

--- 

```{r }
dat$predict5 <- predict(model5, newdata = dat)
(ggplot(data=dat, aes(Height, Wr.Hnd)) + geom_point() + geom_line(aes(y=predict3), lwd=1))+
(ggplot(data=dat, aes(Height, Wr.Hnd, color=Sex)) + geom_point() + geom_line(aes(y=predict4), lwd=1) +scale_color_manual(values=c("black", "red"))) + 
(ggplot(data=dat, aes(Height, Wr.Hnd, color=Sex)) + geom_point() + geom_line(aes(y=predict5), lwd=1) +scale_color_manual(values=c("black", "red"))) + plot_layout(guides="collect")
```

## Model comparison

ANOVA compares the improvement in fit between models to the improvement that would be expected if there was no real change.

```{r }
anova(model3, model4, model5)
```

# Extensions

## Everything is a linear model

What statistical tests/procedures have we replaced with a linear model?

* Unpaired T-test
* Correlation
* ANOVA
* ANCOVA

All other statistical tests can be reframed in this way:

* Models for count or categorical outcomes
* Non-parametric tests
* Non-linear models
* More complex machine learning


## Dealing with non-normal data

* So far weâ€™ve seen data that can be modelled using normal distributions.

* Biological data very often does not act like this

* What options do we have?

## Animal traits

```{r }
animals <- read.csv("observations.csv")
library(ggplot2)
ggplot(animals, aes(body.mass,metabolic.rate,col=phylum)) + geom_point() + scale_x_log10() + scale_y_log10() + facet_wrap(~phylum)

```

## Logarithmic transformations

Instead of modelling on y, we can model log(y).

* This is a very commonly used approach and it is surprising how often and how well it works.

$$\log(y_i) = a + bx_i + \epsilon_i$$

* Implies

$$y_i = \exp(a + bx + e) = e^a\times e^{bx_i}\times e^{\epsilon_i}$$

or 

$$y_i = \alpha\times \beta^{x_i}\times e^{\epsilon_i}$$

* So instead of an additive model, we have a multiplicative one.

* But we estimate it as a regular linear model, using $\log(y)$ as the outcome.

